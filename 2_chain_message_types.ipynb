{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Message Types\n"
      ],
      "metadata": {
        "id": "FNa3Mnm46fyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFJ_yVXF10oT",
        "outputId": "eadf134c-9a6a-4a43-f849-2016327eb854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.63)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "messages = [AIMessage(content='so you are researching about history', name = 'Model')]\n",
        "messages.extend([HumanMessage(content='yes', name = 'Human')])\n",
        "messages.extend([AIMessage(content='greate, what you want to learn', name = 'Model')])\n",
        "# messages.extend([HumanMessage(content='best place to start',name = 'Human')])\n",
        "\n",
        "for m in messages:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqEPyJcJ17hY",
        "outputId": "47909141-db39-484c-f219-5d8ecb91c630"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Model\n",
            "\n",
            "so you are researching about history\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Human\n",
            "\n",
            "yes\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Model\n",
            "\n",
            "greate, what you want to learn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4zvwzvu3_vX",
        "outputId": "28f4e773-d9b5-4e7f-a51d-bbd6b5151aa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.64 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.84.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Collecting langsmith<0.4,>=0.3.45 (from langchain-core<1.0.0,>=0.3.64->langchain_openai)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain_openai) (4.14.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain_openai) (2.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.64->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.21-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langsmith, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.44\n",
            "    Uninstalling langsmith-0.3.44:\n",
            "      Successfully uninstalled langsmith-0.3.44\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "Successfully installed langchain-core-0.3.64 langchain_openai-0.3.21 langsmith-0.3.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "def _set_env(var:str):\n",
        "  if not os.environ.get(var):\n",
        "    os.environ[var]=getpass.getpass(f'Enter {var}:')\n",
        "\n",
        "_set_env('OPENAI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWAiiGkl5BKA",
        "outputId": "a9981c27-e22e-4281-bf3c-94cfa7ba0d6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OPENAI_API_KEY:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 0)\n",
        "result = llm.invoke(messages)\n",
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "iO3LMqFi3EUT",
        "outputId": "b97972a9-f5b9-4016-be75-45f07b6140b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 149);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZPkPyRy37M5",
        "outputId": "483afb8e-a978-4ead-8f4b-d3539161a781"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='about history?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 36, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bgx9185BC1SrEhUaO1jCYArfAU2Tx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3c722c7e-f7ec-473c-9425-922f19e64729-0', usage_metadata={'input_tokens': 36, 'output_tokens': 3, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [AIMessage(content='so you are researching about history', name = 'Model')]\n",
        "messages.extend([HumanMessage(content='yes', name = 'Human')])\n",
        "messages.extend([AIMessage(content='greate, what you want to learn', name = 'Model')])\n",
        "messages.extend([HumanMessage(content='best place to start',name = 'Human')])"
      ],
      "metadata": {
        "id": "HnUsI5gU501h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(messages)\n",
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "4KUc3lgl6PlZ",
        "outputId": "23bb86a8-8ca8-4d6f-c373-64d41286d80d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 149);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVkzq2-S6TlD",
        "outputId": "1c3e7aed-5903-436f-b6f4-4575590a2630"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"A good place to start when researching history is to identify a specific time period, region, or topic that interests you. Once you have a focus, you can begin by exploring general overviews, textbooks, and online resources to gain a broad understanding of the subject. From there, you can delve deeper into more specialized sources such as academic journals, primary documents, and historical archives to further your research. It's also helpful to consult with historians, professors, or experts in the field to gain insights and guidance on your research journey.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 46, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BgxAbh1v4dwuwFNX3uVDEgujeot6l', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5482d01f-cec9-43a7-a121-e0d5cc6528a8-0', usage_metadata={'input_tokens': 46, 'output_tokens': 106, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ls0549kU6Uy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Tools"
      ],
      "metadata": {
        "id": "Ja_xHieu6m5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a: int, b:int)->int :\n",
        "  '''\n",
        "     multiply a and b.\n",
        "\n",
        "     Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "  '''\n",
        "  return a*b\n",
        "\n",
        "def polygon(a: int, b:int)->int :\n",
        "  '''\n",
        "     returns the poligon of two int numbers a and b. this should run only when asked for polygon value.\n",
        "\n",
        "     Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "  '''\n",
        "  return (a*b)*(a+b)+1\n",
        "\n",
        "llm_with_tools = llm.bind_tools([multiply,polygon])"
      ],
      "metadata": {
        "id": "ehexkIje6pOH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call = llm_with_tools.invoke([HumanMessage(content='what is 3 times 4  ')])\n",
        "tool_call.additional_kwargs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tyk2YpC7RY_",
        "outputId": "e4e40d7e-56a9-4222-b8d6-fc7d2e827432"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tool_calls': [{'id': 'call_tkrulYf2R4aLFVVUOEwVdD1D',\n",
              "   'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'multiply'},\n",
              "   'type': 'function'}],\n",
              " 'refusal': None}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QoSRD9Gf7ccL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Messages State"
      ],
      "metadata": {
        "id": "Tjw6Cnjo_LVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# usign reduces\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langchain_core.messages import AnyMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class MessageState(TypedDict):\n",
        "  messages: Annotated[list[AnyMessage],add_messages]\n",
        "\n",
        "#But langgraph have pre built MessageState"
      ],
      "metadata": {
        "id": "isCIKJpY_M1n"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState\n",
        "\n",
        "class State(MessagesState):\n",
        "  # add any keys needed beyond messages, witch is pre built\n",
        "  pass"
      ],
      "metadata": {
        "id": "CMgTuyMk_PM3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_messages = [AIMessage(content='so you are researching about history', name = 'Model'), HumanMessage(content='yes', name = 'Human')]\n",
        "new_message = AIMessage(content='great', name = 'Model')\n",
        "add_messages(initial_messages, new_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU26kJ8QAVF_",
        "outputId": "4663bc9a-7a89-450d-cfa2-b8bc9e9f2945"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='so you are researching about history', additional_kwargs={}, response_metadata={}, name='Model', id='9957c97d-5a15-4407-af60-7b6af9b676cf'),\n",
              " HumanMessage(content='yes', additional_kwargs={}, response_metadata={}, name='Human', id='3da4e2b9-ff26-442d-854a-839797f85ca2'),\n",
              " AIMessage(content='great', additional_kwargs={}, response_metadata={}, name='Model', id='86d15433-326d-437e-b699-725a2260f07e')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_8NgS_OQWEB",
        "outputId": "4d1cdeba-7450-45ad-88d9-8421d4339964"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='so you are researching about history', additional_kwargs={}, response_metadata={}, name='Model', id='9957c97d-5a15-4407-af60-7b6af9b676cf'),\n",
              " HumanMessage(content='yes', additional_kwargs={}, response_metadata={}, name='Human', id='3da4e2b9-ff26-442d-854a-839797f85ca2')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuP7aFMvQaia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph"
      ],
      "metadata": {
        "id": "QA0XDnnRRFc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "class MessagesState(MessagesState):\n",
        "  #additional keys\n",
        "  pass\n",
        "\n",
        "#node\n",
        "def tool_call_llm(state: MessagesState):\n",
        "  return {\"messages\": [llm_with_tools.invoke(state['messages'])]}\n",
        "\n",
        "#build graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node('tool_call_llm',tool_call_llm)\n",
        "builder.add_edge(START, 'tool_call_llm')\n",
        "builder.add_edge('tool_call_llm', END)\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "iSbsO89aRHFI",
        "outputId": "3875fa51-b36c-4d69-a448-b11aeb5205ed"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = graph.invoke({\"messages\":HumanMessage(content='Hello')})\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcyufjqLSTk0",
        "outputId": "ec10f6be-7243-4968-e578-459216620287"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='9d9dafcf-82ef-4325-9bd4-d40485e85686'),\n",
              "  AIMessage(content='Hi! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 105, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BgypvRkdAWedZ3VY6mpKy8HEkCDae', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--250b5dec-1bc7-48cb-bf36-14bde712f313-0', usage_metadata={'input_tokens': 105, 'output_tokens': 10, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = graph.invoke({\"messages\":HumanMessage(content='what is 2 * 6')})\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ9DqZE8Svtu",
        "outputId": "1fa029d4-be87-4948-9693-5fc5e76ff91c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is 2 * 6', additional_kwargs={}, response_metadata={}, id='4b492737-cd9c-4430-8b5c-cb172b0f760f'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cr9PxFB6KQE8icsQFmq9RYxm', 'function': {'arguments': '{\"a\":2,\"b\":6}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 111, 'total_tokens': 128, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BgyqouNJBHQCzUNtZncdmlaSPBqNn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--118890f9-3d1e-41b3-9061-a478916b2243-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 6}, 'id': 'call_cr9PxFB6KQE8icsQFmq9RYxm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 111, 'output_tokens': 17, 'total_tokens': 128, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTE - LLM decide witch tool to call, it does not call and get result by itself"
      ],
      "metadata": {
        "id": "MIv-CA5cS89l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}